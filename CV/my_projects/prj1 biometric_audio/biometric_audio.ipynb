{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T16:59:22.858602Z",
     "start_time": "2024-04-05T16:59:19.928070Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.special import softmax\n",
    "from random import uniform\n",
    "from math import cos, sin, pi"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples = 70000\n",
    "n_mels = 128\n",
    "h_features = 168\n",
    "w_features = 137\n",
    "num_audio = 13936"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T16:59:22.864054Z",
     "start_time": "2024-04-05T16:59:22.860601Z"
    }
   },
   "id": "f5c219484eca4ad4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T16:59:22.903336Z",
     "start_time": "2024-04-05T16:59:22.867049Z"
    }
   },
   "id": "e9136d72cbcab22",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "targets = open(\"./train/targets.tsv\",\"r\")\n",
    "y_dict = {}\n",
    "\n",
    "for line in targets:\n",
    "    line = line.split()\n",
    "    y_dict[line[0]] = int(line[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T16:59:22.930036Z",
     "start_time": "2024-04-05T16:59:22.904356Z"
    }
   },
   "id": "d5745b153f1909c9",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 1000\n"
     ]
    }
   ],
   "source": [
    "X = np.empty((num_audio, h_features, w_features), dtype=np.float64)\n",
    "y = np.empty(num_audio, dtype=int)\n",
    "i = 0\n",
    "\n",
    "for file in os.listdir(\"./train\"):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audio, sr = librosa.load(f\"./train/{filename}\")\n",
    "        \n",
    "        #Trim silence\n",
    "        if len(audio)> 0:\n",
    "            audio, _ = librosa.effects.trim(audio)\n",
    "\n",
    "        #Trim if audio length > samples \n",
    "        if len(audio) > samples:\n",
    "            audio = audio[0:0+samples]\n",
    "        \n",
    "        #Else pad blanks if shorter \n",
    "        else:\n",
    "            padding = samples - len(audio)\n",
    "            offset = padding // 2\n",
    "            audio = np.pad(audio, (offset, samples - len(audio) - offset), \"mean\")\n",
    "        \n",
    "        #Get Mel spectogram of audio\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio,\n",
    "                                                     sr=sr,\n",
    "                                                     n_mels=n_mels)\n",
    "        #Convert to log scale (DB)\n",
    "        spectrogram = librosa.power_to_db(spectrogram)\n",
    "        # print(spectrogram.shape, end=\" \")\n",
    "        \n",
    "        #Get MFCC and second derivatives\n",
    "        mfcc = librosa.feature.mfcc(S=spectrogram)\n",
    "        \n",
    "        delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "        \n",
    "        #Append MFCC to spectrogram and flatten\n",
    "        features = np.concatenate((spectrogram,mfcc,delta2_mfcc),axis=0)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Processed {i}')\n",
    "        \n",
    "        \n",
    "        if i == 1024:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        X[i] = features\n",
    "        y[i] = y_dict[filename[:-4]]\n",
    "        i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:22:49.234254Z",
     "start_time": "2024-04-05T18:22:26.463706Z"
    }
   },
   "id": "8a0a439f2065ffe6",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y, dtype=torch.int64, device=device)\n",
    "X = X.reshape((num_audio, 1, 168, 137))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:22:58.963712Z",
     "start_time": "2024-04-05T18:22:58.108825Z"
    }
   },
   "id": "c6518ef26939bd7",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = X[:1024]\n",
    "y = y[:1024]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:22:58.971686Z",
     "start_time": "2024-04-05T18:22:58.966715Z"
    }
   },
   "id": "b53f1878d3923805",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1024, 1, 168, 137]),\n torch.float32,\n torch.Size([1024]),\n torch.int64)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, y.shape, y.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:07:49.457501Z",
     "start_time": "2024-04-05T17:07:49.451971Z"
    }
   },
   "id": "8f544085a0a83bcf",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = TensorDataset(X, y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "loaders = {\"train\": train_dataloader}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:25:32.817998Z",
     "start_time": "2024-04-05T18:25:32.813401Z"
    }
   },
   "id": "6c5b2873007d9e22",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[[-3.9163e+01, -3.8709e+01, -3.8502e+01,  ..., -3.2786e+01,\n            -3.7995e+01, -3.8318e+01],\n           [-4.8700e+01, -5.2733e+01, -5.2704e+01,  ..., -3.4232e+01,\n            -4.6748e+01, -5.1451e+01],\n           [-5.2726e+01, -5.2733e+01, -5.2733e+01,  ..., -2.9987e+01,\n            -4.4160e+01, -5.2733e+01],\n           ...,\n           [ 2.0176e-02,  2.0176e-02,  2.0176e-02,  ..., -4.7059e-02,\n            -4.7059e-02, -4.7059e-02],\n           [-7.1335e-02, -7.1335e-02, -7.1335e-02,  ..., -4.0950e-01,\n            -4.0950e-01, -4.0950e-01],\n           [-8.5954e-02, -8.5954e-02, -8.5954e-02,  ...,  5.5621e-01,\n             5.5621e-01,  5.5621e-01]]],\n \n \n         [[[-3.1075e+01, -2.2716e+01, -2.5695e+01,  ..., -4.0714e+01,\n            -4.5393e+01, -3.8303e+01],\n           [-3.2313e+01, -2.0403e+01, -1.7515e+01,  ..., -3.0716e+01,\n            -3.3296e+01, -3.0829e+01],\n           [-3.5557e+01, -2.4091e+01, -2.1740e+01,  ..., -3.3820e+01,\n            -3.5691e+01, -3.3292e+01],\n           ...,\n           [ 1.0998e+00,  1.0998e+00,  1.0998e+00,  ...,  6.7135e-01,\n             6.7135e-01,  6.7135e-01],\n           [-1.7219e-01, -1.7219e-01, -1.7219e-01,  ..., -1.7075e+00,\n            -1.7075e+00, -1.7075e+00],\n           [ 2.6057e-01,  2.6057e-01,  2.6057e-01,  ...,  1.5458e+00,\n             1.5458e+00,  1.5458e+00]]],\n \n \n         [[[-5.4125e+01, -3.4448e+01, -2.5053e+01,  ..., -3.1473e+01,\n            -3.0502e+01, -2.8579e+01],\n           [-5.4125e+01, -4.2362e+01, -3.6981e+01,  ..., -3.2428e+01,\n            -3.0186e+01, -2.7187e+01],\n           [-5.4125e+01, -4.4025e+01, -3.7382e+01,  ..., -3.0682e+01,\n            -3.1955e+01, -2.9957e+01],\n           ...,\n           [ 2.4051e-01,  2.4051e-01,  2.4051e-01,  ..., -4.7056e-01,\n            -4.7056e-01, -4.7056e-01],\n           [ 2.1529e-01,  2.1529e-01,  2.1529e-01,  ...,  5.3512e-02,\n             5.3512e-02,  5.3512e-02],\n           [ 1.0834e-01,  1.0834e-01,  1.0834e-01,  ...,  3.9244e-01,\n             3.9244e-01,  3.9244e-01]]],\n \n \n         ...,\n \n \n         [[[-5.0311e+01, -2.4186e+01, -2.1386e+01,  ..., -2.1959e+01,\n            -2.2524e+01, -2.6301e+01],\n           [-5.0206e+01, -2.5629e+01, -1.7977e+01,  ..., -1.9547e+01,\n            -1.6789e+01, -2.0599e+01],\n           [-5.0962e+01, -2.6695e+01, -2.0763e+01,  ..., -2.0994e+01,\n            -1.6897e+01, -1.5039e+01],\n           ...,\n           [ 3.0042e-01,  3.0042e-01,  3.0042e-01,  ...,  1.7604e-01,\n             1.7604e-01,  1.7604e-01],\n           [ 4.5736e-01,  4.5736e-01,  4.5736e-01,  ...,  7.0398e-03,\n             7.0398e-03,  7.0398e-03],\n           [ 1.3377e-01,  1.3377e-01,  1.3377e-01,  ..., -2.9164e-01,\n            -2.9164e-01, -2.9164e-01]]],\n \n \n         [[[-3.9738e+01, -2.5284e+01, -2.3109e+01,  ..., -3.1055e+01,\n            -3.0870e+01, -3.1165e+01],\n           [-4.7525e+01, -3.3804e+01, -2.5700e+01,  ..., -3.0198e+01,\n            -3.0039e+01, -3.2056e+01],\n           [-4.3524e+01, -3.2340e+01, -2.6909e+01,  ..., -4.0869e+01,\n            -3.9016e+01, -3.7250e+01],\n           ...,\n           [ 3.0728e-01,  3.0728e-01,  3.0728e-01,  ...,  2.2467e-02,\n             2.2467e-02,  2.2467e-02],\n           [-6.6783e-01, -6.6783e-01, -6.6783e-01,  ..., -1.3194e-01,\n            -1.3194e-01, -1.3194e-01],\n           [-3.3928e-01, -3.3928e-01, -3.3928e-01,  ..., -1.3187e+00,\n            -1.3187e+00, -1.3187e+00]]],\n \n \n         [[[-3.9146e+01, -3.8695e+01, -3.9638e+01,  ..., -3.9638e+01,\n            -3.9600e+01, -3.8301e+01],\n           [-4.8683e+01, -5.4394e+01, -6.6014e+01,  ..., -6.6014e+01,\n            -6.6014e+01, -5.1434e+01],\n           [-5.2709e+01, -5.8775e+01, -6.6014e+01,  ..., -6.6014e+01,\n            -6.6014e+01, -5.5611e+01],\n           ...,\n           [ 2.8422e-02,  2.8422e-02,  2.8422e-02,  ...,  7.9277e-02,\n             7.9277e-02,  7.9277e-02],\n           [ 8.5994e-03,  8.5994e-03,  8.5994e-03,  ...,  5.9593e-02,\n             5.9593e-02,  5.9593e-02],\n           [-7.1867e-03, -7.1867e-03, -7.1867e-03,  ...,  4.1272e-02,\n             4.1272e-02,  4.1272e-02]]]], device='cuda:0'),\n tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0'))"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:25:48.800869Z",
     "start_time": "2024-04-05T18:25:48.770158Z"
    }
   },
   "id": "443d17db5d2ce0b6",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:01:57.438543Z",
     "start_time": "2024-04-05T17:01:57.431679Z"
    }
   },
   "id": "c12198b1f15a91",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "\n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride),\n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:01:57.450172Z",
     "start_time": "2024-04-05T17:01:57.439553Z"
    }
   },
   "id": "f6a794af1cc63a18",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.float32, torch.Size([1, 168, 137]))"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].dtype, train_dataset[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:01:57.457215Z",
     "start_time": "2024-04-05T17:01:57.451183Z"
    }
   },
   "id": "5dfaf68ec800afbd",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[-3.9163e+01, -3.8709e+01, -3.8502e+01,  ..., -3.2786e+01,\n           -3.7995e+01, -3.8318e+01],\n          [-4.8700e+01, -5.2733e+01, -5.2704e+01,  ..., -3.4232e+01,\n           -4.6748e+01, -5.1451e+01],\n          [-5.2726e+01, -5.2733e+01, -5.2733e+01,  ..., -2.9987e+01,\n           -4.4160e+01, -5.2733e+01],\n          ...,\n          [ 2.0176e-02,  2.0176e-02,  2.0176e-02,  ..., -4.7059e-02,\n           -4.7059e-02, -4.7059e-02],\n          [-7.1335e-02, -7.1335e-02, -7.1335e-02,  ..., -4.0950e-01,\n           -4.0950e-01, -4.0950e-01],\n          [-8.5954e-02, -8.5954e-02, -8.5954e-02,  ...,  5.5621e-01,\n            5.5621e-01,  5.5621e-01]]], device='cuda:0'),\n tensor(1, device='cuda:0'))"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:24:14.399268Z",
     "start_time": "2024-04-05T18:24:14.384204Z"
    }
   },
   "id": "8ce8061230b61f12",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         ...,\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet_18(1, 2)\n",
    "batch = []\n",
    "next(iter(train_dataloader))\n",
    "# model.forward(batch[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:20:58.582780Z",
     "start_time": "2024-04-05T17:20:54.978974Z"
    }
   },
   "id": "8ff57249ffbf09d4",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, max_epochs, lr_scheduler = None):\n",
    "    accuracy = {\"train\": [], \"valid\": []}\n",
    "    print(1, y)\n",
    "    for epoch in range(max_epochs):\n",
    "        print(2, y)\n",
    "        for k, dataloader in loaders.items():\n",
    "            print(3, y)\n",
    "            epoch_correct = 0\n",
    "            epoch_all = 0\n",
    "            for x_batch, y_batch in dataloader:\n",
    "                print(4, y)\n",
    "                # x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                # y_batch = y_batch.type(torch.LongTensor).to(device)\n",
    "                if k == \"train\":\n",
    "                    model.train()\n",
    "                    outp = model(x_batch)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(outp, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        outp = model(x_batch)\n",
    "                preds = outp.argmax(-1)\n",
    "                correct = (y_batch == preds).sum().item()\n",
    "                epoch_correct += correct\n",
    "                epoch_all += BATCH_SIZE\n",
    "\n",
    "            if k == \"train\":\n",
    "                print(f\"Epoch: {epoch+1}\")\n",
    "            print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n",
    "            accuracy[k].append(epoch_correct/epoch_all)\n",
    "        \n",
    "        # if k == \"train\" and lr_scheduler is not None:\n",
    "        #     lr_scheduler.step(epoch_correct/epoch_all)\n",
    "            \n",
    "    return accuracy[\"valid\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:01:57.470693Z",
     "start_time": "2024-04-05T17:01:57.462317Z"
    }
   },
   "id": "cf6ed84379db9793",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_,y_ = X.clone(),y.clone()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:07:58.870077Z",
     "start_time": "2024-04-05T17:07:58.866291Z"
    }
   },
   "id": "7ee234ff4eec8e53",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X,y = X_.clone(), y_.clone()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:25:27.078193Z",
     "start_time": "2024-04-05T18:25:27.074062Z"
    }
   },
   "id": "3a6b9b479c6f772c",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_dataloader:\n",
    "    print(type(x_batch))\n",
    "    # print(x_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:27:13.454972Z",
     "start_time": "2024-04-05T18:27:09.934655Z"
    }
   },
   "id": "f26f8e69de6a05c8",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-3.9163e+01, -3.8709e+01, -3.8502e+01,  ..., -3.2786e+01,\n           -3.7995e+01, -3.8318e+01],\n          [-4.8700e+01, -5.2733e+01, -5.2704e+01,  ..., -3.4232e+01,\n           -4.6748e+01, -5.1451e+01],\n          [-5.2726e+01, -5.2733e+01, -5.2733e+01,  ..., -2.9987e+01,\n           -4.4160e+01, -5.2733e+01],\n          ...,\n          [ 2.0176e-02,  2.0176e-02,  2.0176e-02,  ..., -4.7059e-02,\n           -4.7059e-02, -4.7059e-02],\n          [-7.1335e-02, -7.1335e-02, -7.1335e-02,  ..., -4.0950e-01,\n           -4.0950e-01, -4.0950e-01],\n          [-8.5954e-02, -8.5954e-02, -8.5954e-02,  ...,  5.5621e-01,\n            5.5621e-01,  5.5621e-01]]],\n\n\n        [[[-3.1075e+01, -2.2716e+01, -2.5695e+01,  ..., -4.0714e+01,\n           -4.5393e+01, -3.8303e+01],\n          [-3.2313e+01, -2.0403e+01, -1.7515e+01,  ..., -3.0716e+01,\n           -3.3296e+01, -3.0829e+01],\n          [-3.5557e+01, -2.4091e+01, -2.1740e+01,  ..., -3.3820e+01,\n           -3.5691e+01, -3.3292e+01],\n          ...,\n          [ 1.0998e+00,  1.0998e+00,  1.0998e+00,  ...,  6.7135e-01,\n            6.7135e-01,  6.7135e-01],\n          [-1.7219e-01, -1.7219e-01, -1.7219e-01,  ..., -1.7075e+00,\n           -1.7075e+00, -1.7075e+00],\n          [ 2.6057e-01,  2.6057e-01,  2.6057e-01,  ...,  1.5458e+00,\n            1.5458e+00,  1.5458e+00]]],\n\n\n        [[[-5.4125e+01, -3.4448e+01, -2.5053e+01,  ..., -3.1473e+01,\n           -3.0502e+01, -2.8579e+01],\n          [-5.4125e+01, -4.2362e+01, -3.6981e+01,  ..., -3.2428e+01,\n           -3.0186e+01, -2.7187e+01],\n          [-5.4125e+01, -4.4025e+01, -3.7382e+01,  ..., -3.0682e+01,\n           -3.1955e+01, -2.9957e+01],\n          ...,\n          [ 2.4051e-01,  2.4051e-01,  2.4051e-01,  ..., -4.7056e-01,\n           -4.7056e-01, -4.7056e-01],\n          [ 2.1529e-01,  2.1529e-01,  2.1529e-01,  ...,  5.3512e-02,\n            5.3512e-02,  5.3512e-02],\n          [ 1.0834e-01,  1.0834e-01,  1.0834e-01,  ...,  3.9244e-01,\n            3.9244e-01,  3.9244e-01]]],\n\n\n        ...,\n\n\n        [[[-5.0311e+01, -2.4186e+01, -2.1386e+01,  ..., -2.1959e+01,\n           -2.2524e+01, -2.6301e+01],\n          [-5.0206e+01, -2.5629e+01, -1.7977e+01,  ..., -1.9547e+01,\n           -1.6789e+01, -2.0599e+01],\n          [-5.0962e+01, -2.6695e+01, -2.0763e+01,  ..., -2.0994e+01,\n           -1.6897e+01, -1.5039e+01],\n          ...,\n          [ 3.0042e-01,  3.0042e-01,  3.0042e-01,  ...,  1.7604e-01,\n            1.7604e-01,  1.7604e-01],\n          [ 4.5736e-01,  4.5736e-01,  4.5736e-01,  ...,  7.0398e-03,\n            7.0398e-03,  7.0398e-03],\n          [ 1.3377e-01,  1.3377e-01,  1.3377e-01,  ..., -2.9164e-01,\n           -2.9164e-01, -2.9164e-01]]],\n\n\n        [[[-3.9738e+01, -2.5284e+01, -2.3109e+01,  ..., -3.1055e+01,\n           -3.0870e+01, -3.1165e+01],\n          [-4.7525e+01, -3.3804e+01, -2.5700e+01,  ..., -3.0198e+01,\n           -3.0039e+01, -3.2056e+01],\n          [-4.3524e+01, -3.2340e+01, -2.6909e+01,  ..., -4.0869e+01,\n           -3.9016e+01, -3.7250e+01],\n          ...,\n          [ 3.0728e-01,  3.0728e-01,  3.0728e-01,  ...,  2.2467e-02,\n            2.2467e-02,  2.2467e-02],\n          [-6.6783e-01, -6.6783e-01, -6.6783e-01,  ..., -1.3194e-01,\n           -1.3194e-01, -1.3194e-01],\n          [-3.3928e-01, -3.3928e-01, -3.3928e-01,  ..., -1.3187e+00,\n           -1.3187e+00, -1.3187e+00]]],\n\n\n        [[[-3.9146e+01, -3.8695e+01, -3.9638e+01,  ..., -3.9638e+01,\n           -3.9600e+01, -3.8301e+01],\n          [-4.8683e+01, -5.4394e+01, -6.6014e+01,  ..., -6.6014e+01,\n           -6.6014e+01, -5.1434e+01],\n          [-5.2709e+01, -5.8775e+01, -6.6014e+01,  ..., -6.6014e+01,\n           -6.6014e+01, -5.5611e+01],\n          ...,\n          [ 2.8422e-02,  2.8422e-02,  2.8422e-02,  ...,  7.9277e-02,\n            7.9277e-02,  7.9277e-02],\n          [ 8.5994e-03,  8.5994e-03,  8.5994e-03,  ...,  5.9593e-02,\n            5.9593e-02,  5.9593e-02],\n          [-7.1867e-03, -7.1867e-03, -7.1867e-03,  ...,  4.1272e-02,\n            4.1272e-02,  4.1272e-02]]]], device='cuda:0')"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tensors[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:08:41.251649Z",
     "start_time": "2024-04-05T17:08:41.218756Z"
    }
   },
   "id": "b80cff371ac777fa",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[[-3.9163e+01, -3.8709e+01, -3.8502e+01,  ..., -3.2786e+01,\n            -3.7995e+01, -3.8318e+01],\n           [-4.8700e+01, -5.2733e+01, -5.2704e+01,  ..., -3.4232e+01,\n            -4.6748e+01, -5.1451e+01],\n           [-5.2726e+01, -5.2733e+01, -5.2733e+01,  ..., -2.9987e+01,\n            -4.4160e+01, -5.2733e+01],\n           ...,\n           [ 2.0176e-02,  2.0176e-02,  2.0176e-02,  ..., -4.7059e-02,\n            -4.7059e-02, -4.7059e-02],\n           [-7.1335e-02, -7.1335e-02, -7.1335e-02,  ..., -4.0950e-01,\n            -4.0950e-01, -4.0950e-01],\n           [-8.5954e-02, -8.5954e-02, -8.5954e-02,  ...,  5.5621e-01,\n             5.5621e-01,  5.5621e-01]]],\n \n \n         [[[-3.1075e+01, -2.2716e+01, -2.5695e+01,  ..., -4.0714e+01,\n            -4.5393e+01, -3.8303e+01],\n           [-3.2313e+01, -2.0403e+01, -1.7515e+01,  ..., -3.0716e+01,\n            -3.3296e+01, -3.0829e+01],\n           [-3.5557e+01, -2.4091e+01, -2.1740e+01,  ..., -3.3820e+01,\n            -3.5691e+01, -3.3292e+01],\n           ...,\n           [ 1.0998e+00,  1.0998e+00,  1.0998e+00,  ...,  6.7135e-01,\n             6.7135e-01,  6.7135e-01],\n           [-1.7219e-01, -1.7219e-01, -1.7219e-01,  ..., -1.7075e+00,\n            -1.7075e+00, -1.7075e+00],\n           [ 2.6057e-01,  2.6057e-01,  2.6057e-01,  ...,  1.5458e+00,\n             1.5458e+00,  1.5458e+00]]],\n \n \n         [[[-5.4125e+01, -3.4448e+01, -2.5053e+01,  ..., -3.1473e+01,\n            -3.0502e+01, -2.8579e+01],\n           [-5.4125e+01, -4.2362e+01, -3.6981e+01,  ..., -3.2428e+01,\n            -3.0186e+01, -2.7187e+01],\n           [-5.4125e+01, -4.4025e+01, -3.7382e+01,  ..., -3.0682e+01,\n            -3.1955e+01, -2.9957e+01],\n           ...,\n           [ 2.4051e-01,  2.4051e-01,  2.4051e-01,  ..., -4.7056e-01,\n            -4.7056e-01, -4.7056e-01],\n           [ 2.1529e-01,  2.1529e-01,  2.1529e-01,  ...,  5.3512e-02,\n             5.3512e-02,  5.3512e-02],\n           [ 1.0834e-01,  1.0834e-01,  1.0834e-01,  ...,  3.9244e-01,\n             3.9244e-01,  3.9244e-01]]],\n \n \n         ...,\n \n \n         [[[-5.0311e+01, -2.4186e+01, -2.1386e+01,  ..., -2.1959e+01,\n            -2.2524e+01, -2.6301e+01],\n           [-5.0206e+01, -2.5629e+01, -1.7977e+01,  ..., -1.9547e+01,\n            -1.6789e+01, -2.0599e+01],\n           [-5.0962e+01, -2.6695e+01, -2.0763e+01,  ..., -2.0994e+01,\n            -1.6897e+01, -1.5039e+01],\n           ...,\n           [ 3.0042e-01,  3.0042e-01,  3.0042e-01,  ...,  1.7604e-01,\n             1.7604e-01,  1.7604e-01],\n           [ 4.5736e-01,  4.5736e-01,  4.5736e-01,  ...,  7.0398e-03,\n             7.0398e-03,  7.0398e-03],\n           [ 1.3377e-01,  1.3377e-01,  1.3377e-01,  ..., -2.9164e-01,\n            -2.9164e-01, -2.9164e-01]]],\n \n \n         [[[-3.9738e+01, -2.5284e+01, -2.3109e+01,  ..., -3.1055e+01,\n            -3.0870e+01, -3.1165e+01],\n           [-4.7525e+01, -3.3804e+01, -2.5700e+01,  ..., -3.0198e+01,\n            -3.0039e+01, -3.2056e+01],\n           [-4.3524e+01, -3.2340e+01, -2.6909e+01,  ..., -4.0869e+01,\n            -3.9016e+01, -3.7250e+01],\n           ...,\n           [ 3.0728e-01,  3.0728e-01,  3.0728e-01,  ...,  2.2467e-02,\n             2.2467e-02,  2.2467e-02],\n           [-6.6783e-01, -6.6783e-01, -6.6783e-01,  ..., -1.3194e-01,\n            -1.3194e-01, -1.3194e-01],\n           [-3.3928e-01, -3.3928e-01, -3.3928e-01,  ..., -1.3187e+00,\n            -1.3187e+00, -1.3187e+00]]],\n \n \n         [[[-3.9146e+01, -3.8695e+01, -3.9638e+01,  ..., -3.9638e+01,\n            -3.9600e+01, -3.8301e+01],\n           [-4.8683e+01, -5.4394e+01, -6.6014e+01,  ..., -6.6014e+01,\n            -6.6014e+01, -5.1434e+01],\n           [-5.2709e+01, -5.8775e+01, -6.6014e+01,  ..., -6.6014e+01,\n            -6.6014e+01, -5.5611e+01],\n           ...,\n           [ 2.8422e-02,  2.8422e-02,  2.8422e-02,  ...,  7.9277e-02,\n             7.9277e-02,  7.9277e-02],\n           [ 8.5994e-03,  8.5994e-03,  8.5994e-03,  ...,  5.9593e-02,\n             5.9593e-02,  5.9593e-02],\n           [-7.1867e-03, -7.1867e-03, -7.1867e-03,  ...,  4.1272e-02,\n             4.1272e-02,  4.1272e-02]]]], device='cuda:0'),\n tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'))"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:07:16.184012Z",
     "start_time": "2024-04-05T17:07:16.152785Z"
    }
   },
   "id": "6b5f74a8ad75fbed",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "0 tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "1 tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "2 tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "3 tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "4 tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "4 tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "4 tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "4 tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "Epoch: 1\n",
      "Loader: train. Accuracy: 1.0\n",
      "4 tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1\n",
    "\n",
    "model = ResNet_18(1, 2).to(device)\n",
    "print(-1,y)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "print(0,y)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
    "train_model(model, criterion, optimizer, max_epochs)\n",
    "print(4,y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:00:36.129266Z",
     "start_time": "2024-04-05T17:00:29.076246Z"
    }
   },
   "id": "b9dc10b6e23b7de2",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "del X\n",
    "del y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T17:01:31.866583Z",
     "start_time": "2024-04-05T17:01:31.848186Z"
    }
   },
   "id": "2c3ff1a1bdb695dd",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loader: train. Accuracy: 0.9360085227272728\n",
      "Epoch: 2\n",
      "Loader: train. Accuracy: 0.9414772727272728\n",
      "Epoch: 3\n",
      "Loader: train. Accuracy: 0.9467329545454546\n",
      "Epoch: 4\n",
      "Loader: train. Accuracy: 0.9499289772727273\n",
      "Epoch: 5\n",
      "Loader: train. Accuracy: 0.9530539772727272\n"
     ]
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, max_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T01:35:10.196441Z",
     "start_time": "2024-04-03T00:53:05.196573Z"
    }
   },
   "id": "c06d36c1c3586b03",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-03T01:35:10.198441Z"
    }
   },
   "id": "805279dc9411a1c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "00100026dbdffcd01cde6ee9b9a9d273.wav\n",
      "Processed 1000\n",
      "4e7f12b9dd85e72c30894cbefeba6bb6.wav\n",
      "Processed 2000\n",
      "9767325a483f8943f729495a2607500e.wav\n",
      "Processed 3000\n",
      "e2369bcf621e0e46eecb1e74affbfd92.wav\n"
     ]
    }
   ],
   "source": [
    "num_audio = 3413\n",
    "\n",
    "X = np.empty((num_audio, h_features, w_features), dtype=np.float64)\n",
    "y_name = []\n",
    "i = 0\n",
    "\n",
    "for file in os.listdir(\"./test\"):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audio, sr = librosa.load(f\"./test/{filename}\")\n",
    "\n",
    "        #Trim silence\n",
    "        if len(audio)> 0:\n",
    "            audio, _ = librosa.effects.trim(audio)\n",
    "\n",
    "        #Trim if audio length > samples \n",
    "        if len(audio) > samples:\n",
    "            audio = audio[0:0+samples]\n",
    "\n",
    "        #Else pad blanks if shorter \n",
    "        else:\n",
    "            padding = samples - len(audio)\n",
    "            offset = padding // 2\n",
    "            audio = np.pad(audio, (offset, samples - len(audio) - offset), \"mean\")\n",
    "\n",
    "        #Get Mel spectogram of audio\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio,\n",
    "                                                     sr=sr,\n",
    "                                                     n_mels=n_mels)\n",
    "        #Convert to log scale (DB)\n",
    "        spectrogram = librosa.power_to_db(spectrogram)\n",
    "        # print(spectrogram.shape, end=\" \")\n",
    "\n",
    "        #Get MFCC and second derivatives\n",
    "        mfcc = librosa.feature.mfcc(S=spectrogram)\n",
    "\n",
    "        delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        #Append MFCC to spectrogram and flatten\n",
    "        features = np.concatenate((spectrogram,mfcc,delta2_mfcc),axis=0)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Processed {i}')\n",
    "            print(filename)\n",
    "        X[i] = features\n",
    "        y_name.append(filename[:-4])\n",
    "        # y_name[i] = filename[:-4]\n",
    "        i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:46:03.975317Z",
     "start_time": "2024-04-02T23:44:52.473242Z"
    }
   },
   "id": "7608e595259c3d73",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(3413, torch.Size([13936]))"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_name), y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T18:15:27.356041Z",
     "start_time": "2024-04-02T18:15:27.350238Z"
    }
   },
   "id": "31b35dcb274c02e6",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.int, device=device)\n",
    "X = X.reshape((num_audio, 1, 168, 137))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:46:04.069456Z",
     "start_time": "2024-04-02T23:46:03.978314Z"
    }
   },
   "id": "641a14b8d1512f52",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:54:31.234404Z",
     "start_time": "2024-04-02T23:54:31.230605Z"
    }
   },
   "id": "1c81de7eafece998",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_safe\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:46:04.896640Z",
     "start_time": "2024-04-02T23:46:04.131665Z"
    }
   },
   "id": "d29b757392078610",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = ResNet_18(1, 2)\n",
    "model.load_state_dict(torch.load(\"./model_safe\", map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T19:06:05.597923Z",
     "start_time": "2024-04-02T19:06:04.883395Z"
    }
   },
   "id": "531d27b0778be5fe",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = []\n",
    "for x_batch in test_dataloader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_batch= x_batch[0].to(device)\n",
    "        y.append(model(x_batch))\n",
    "    # print(x_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:56:06.429262Z",
     "start_time": "2024-04-02T23:54:53.046948Z"
    }
   },
   "id": "150e4fa63963fc0",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3413"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:46:33.244409Z",
     "start_time": "2024-04-02T23:46:33.237490Z"
    }
   },
   "id": "1a8e36012891142c",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f = open(\"answer.txt\", \"w\")\n",
    "for i in range(num_audio):\n",
    "    f.write(f'{y[i].argmax(-1).item()}\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:56:07.680271Z",
     "start_time": "2024-04-02T23:56:06.431272Z"
    }
   },
   "id": "9ff785373a9b526",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f = open(\"answer.txt\", \"w\")\n",
    "for i in range(num_audio):\n",
    "    f.write(f'{y_name[i]} {y[i].argmax(-1).item()}\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:46:36.172336Z",
     "start_time": "2024-04-02T23:46:35.656783Z"
    }
   },
   "id": "1f6ae6d4eeb39b10",
   "execution_count": 78
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
