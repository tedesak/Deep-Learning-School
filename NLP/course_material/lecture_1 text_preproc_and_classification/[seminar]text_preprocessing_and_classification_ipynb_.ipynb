{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "11.8333px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.717px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PcL7r1hqySq"
   },
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-sGLT0vp4jt"
   },
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn8EWAjnr18g"
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "btBdBLxbgrNV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2b7bad08-1f4e-4be2-aa52-6b9f3be665f1",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:14.774243Z",
     "start_time": "2024-07-02T19:50:10.386710Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\koman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eq-QOD9NlO_Q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cb604c1f-f578-4bf1-843f-51659e6e2c95",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:20.344979Z",
     "start_time": "2024-07-02T19:50:20.315554Z"
    }
   },
   "source": [
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "tokens = word_tokenize(data.lower())\n",
    "print(tokens)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eFDKUzkS6Mci",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f0c94e1a-2074-486a-83dd-16adca9a966a",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:21.656207Z",
     "start_time": "2024-07-02T19:50:21.646128Z"
    }
   },
   "source": [
    "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was going home when she rung.', 'It was a surprise.']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQoG7qznyuf5"
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPeApu2mwYxY"
   },
   "source": [
    "[Razdel](https://natasha.github.io/razdel/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TwJj5Z2fvbeN",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:39.838238Z",
     "start_time": "2024-07-02T19:50:25.175175Z"
    }
   },
   "source": [
    "!pip install -q razdel"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy58Xd_vve-z",
    "outputId": "a97c093a-226a-4418-ddb3-369e2223e696",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:42.509853Z",
     "start_time": "2024-07-02T19:50:42.467028Z"
    }
   },
   "source": [
    "from razdel import tokenize, sentenize\n",
    "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
    "list(tokenize(text))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[Substring(0, 13, 'Кружка-термос'),\n Substring(14, 16, 'на'),\n Substring(17, 20, '0.5'),\n Substring(20, 21, 'л'),\n Substring(22, 23, '('),\n Substring(23, 28, '50/64'),\n Substring(29, 32, 'см³'),\n Substring(32, 33, ','),\n Substring(34, 37, '516'),\n Substring(37, 38, ';'),\n Substring(38, 41, '...'),\n Substring(41, 42, ')')]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrmhCpNdQo6r"
   },
   "source": [
    "#### Регулярные выражения\n",
    "\n",
    "Исчерпывающий пост https://habr.com/ru/post/349860/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IccRpcG06Mfd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2a5860f2-0134-4020-f3ba-f2c774c11203",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:44.618368Z",
     "start_time": "2024-07-02T19:50:44.609258Z"
    }
   },
   "source": [
    "import re\n",
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall('[abc]|up|super', word)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Je8YPHLZPJW7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f9d49f5-d4df-450c-c42b-11453023ca5d",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:45.630285Z",
     "start_time": "2024-07-02T19:50:45.621063Z"
    }
   },
   "source": [
    "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312')"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['49', '432', '312']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fzde8MX1PJXA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "c98053f6-4087-4581-ecb5-db8368c18c52",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:46.436085Z",
     "start_time": "2024-07-02T19:50:46.427680Z"
    }
   },
   "source": [
    "re.sub('[,\\.?!]','','How, to? split. text!')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'How to split text'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GyswV9nuPJXF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8ca28c5b-33fd-44dc-d15d-f170a94bafe3",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:46.947289Z",
     "start_time": "2024-07-02T19:50:46.937342Z"
    }
   },
   "source": [
    "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['I', 'can', 'play', 'football']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz0wIRkRswOQ"
   },
   "source": [
    "### Удаление неинформативных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trdPOBM2jEMf"
   },
   "source": [
    "#### N-граммы\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YYEBfCxLic3R",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e73a357a-c8e7-4338-efa1-6a7f40ad52d4",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:49.516018Z",
     "start_time": "2024-07-02T19:50:49.508808Z"
    }
   },
   "source": [
    "unigram = list(nltk.ngrams(tokens, 1))\n",
    "bigram = list(nltk.ngrams(tokens, 2))\n",
    "print(unigram[:5])\n",
    "print(bigram[:5])"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
      "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1AFeZqejmWwN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4da8e7e2-3405-4a36-86de-0edc20d790e0",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:51.359757Z",
     "start_time": "2024-07-02T19:50:51.352038Z"
    }
   },
   "source": [
    "from nltk import FreqDist\n",
    "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
    "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
      "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W3jJ56hnBFu"
   },
   "source": [
    "#### Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sIBwQ3nBnEfV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "964de8f8-12bf-4a90-e7ae-cec8b90a224c",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:53.625694Z",
     "start_time": "2024-07-02T19:50:53.366300Z"
    }
   },
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\koman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o1nk-TqEslRl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d91efc04-9069-443e-f5de-4edf68baca43",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:54.788575Z",
     "start_time": "2024-07-02T19:50:54.771133Z"
    }
   },
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'further', 'just', 'themselves', 'wasn', 'needn', 'has', 'before', 'through', 'this', 'over', 'they', 'more', 'out', 'didn', 'nor', 'some', 've', 'hadn', 'myself', 'or', 'up', 'from', 'is', 'did', 'he', 'be', 'had', 'hers', 'for', 'your', 'of', \"should've\", \"mightn't\", 'these', 'will', 'them', \"you've\", \"doesn't\", 'what', 'itself', \"couldn't\", 'ours', 'hasn', 'all', 'again', 'both', 'against', 'mustn', 'on', 'its', 'when', \"won't\", \"didn't\", 'y', 'can', 'shan', 'does', 'and', 'into', 'those', 'whom', 'same', 't', 'here', 'then', 'him', 'she', 'by', 'ma', 'below', 'at', 'about', 'll', 'was', 'until', 'herself', 'the', 'than', 'don', 'not', 'do', \"needn't\", 'were', \"you're\", 'yourselves', \"that'll\", 'which', 'as', 'down', 'other', 'in', 'so', 'yours', \"don't\", \"haven't\", 'won', 'weren', 'it', 'between', 'most', 'shouldn', 'having', 'have', 'should', 'are', 'ain', 'we', \"you'd\", 'haven', \"wasn't\", \"hadn't\", 'wouldn', 'why', \"isn't\", 'her', 'once', 'am', 'being', 'how', 'while', 'any', 'with', 'yourself', 'theirs', 'only', \"weren't\", 'isn', 'himself', 'an', \"she's\", 'who', 'after', 'there', 'my', 'to', 'a', \"mustn't\", 'where', 'few', 'no', 're', 'couldn', \"aren't\", 'd', 'you', 'during', 'off', 'doesn', \"it's\", 'ourselves', \"shouldn't\", 'been', 'under', 'our', \"hasn't\", 'mightn', 'each', 'too', 'i', 'because', 'his', 'their', 'now', 'me', 'doing', 'own', 'but', 'aren', \"shan't\", 'm', 'if', \"you'll\", 'o', \"wouldn't\", 'such', 'above', 'that', 's'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KFkfJm9ktAVa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7300933a-e801-4a3e-fbeb-11c218cc4f32",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:55.736657Z",
     "start_time": "2024-07-02T19:50:55.728467Z"
    }
   },
   "source": [
    "print([word for word in tokens if word not in stopWords])"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5QoqlHiS83f",
    "outputId": "53c00e91-b5f3-4530-b7e8-9d6030212f1f",
    "ExecuteTime": {
     "end_time": "2024-07-02T19:50:56.616039Z",
     "start_time": "2024-07-02T19:50:56.609677Z"
    }
   },
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-MYv6e-skM"
   },
   "source": [
    "#### Стемминг vs Лемматизация\n",
    "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
    "* ‘Caring’ -> Стемминг -> ‘Car’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAUKc1oTiQjf"
   },
   "source": [
    "### Стемминг\n",
    "* процесс нахождения основы слова для заданного исходного слова"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iRVu-TrON4sq",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:06.814075Z",
     "start_time": "2024-07-06T10:38:06.117185Z"
    }
   },
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
    "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L9HTGfsBN9eX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2c39c65e-e46a-491a-e935-f1de7c591bda",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:06.824002Z",
     "start_time": "2024-07-06T10:38:06.816202Z"
    }
   },
   "source": [
    "ps = PorterStemmer()\n",
    "list(map(ps.stem, words))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['game', 'game', 'game', 'game', 'compact']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U5qZkB-oODkW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0a18cae1-ec47-41aa-d155-9e21bdbb5ba6",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:06.887075Z",
     "start_time": "2024-07-06T10:38:06.826113Z"
    }
   },
   "source": [
    "ss = SnowballStemmer(language='russian')\n",
    "list(map(ss.stem, words_ru))"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTXbi9FJXr1"
   },
   "source": [
    "### Лематизация\n",
    "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QF4nnEz00thb",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:07.035514Z",
     "start_time": "2024-07-06T10:38:06.889173Z"
    }
   },
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "\n",
    "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно\n",
    "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на\n",
    "устаревших представлениях об устройстве мозга, несовместимо с современной\n",
    "неврологией и содержит ряд фактических ошибок.\"\"\""
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mljfOAC4n21I",
    "outputId": "4a298d6f-e998-4564-f79a-a81df0fd0438",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:17.589412Z",
     "start_time": "2024-07-06T10:38:07.148342Z"
    }
   },
   "source": [
    "!pip install -q pymorphy2"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Zez7jnXl5uJ",
    "outputId": "b10b2ff1-221b-4bc2-b9ab-1732fdc5dcdc",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:18.796285Z",
     "start_time": "2024-07-06T10:38:17.591528Z"
    }
   },
   "source": [
    "# 1\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
    "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 1\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpymorphy2\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m morph \u001B[38;5;241m=\u001B[39m pymorphy2\u001B[38;5;241m.\u001B[39mMorphAnalyzer()\n\u001B[0;32m      4\u001B[0m pymorphy_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: morph\u001B[38;5;241m.\u001B[39mparse(x), raw_ru\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)))\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([res[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnormal_form \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m pymorphy_results]))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001B[0m, in \u001B[0;36mMorphAnalyzer.__init__\u001B[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result_type_orig \u001B[38;5;241m=\u001B[39m result_type\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_char_substitutes(char_substitutes)\n\u001B[1;32m--> 224\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_units(units)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001B[0m, in \u001B[0;36mMorphAnalyzer._init_units\u001B[1;34m(self, units_unbound)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m unit \u001B[38;5;129;01min\u001B[39;00m item[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 235\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_units\u001B[38;5;241m.\u001B[39mappend((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_unit(unit), \u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_units\u001B[38;5;241m.\u001B[39mappend((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_unit(item[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001B[0m, in \u001B[0;36mMorphAnalyzer._bound_unit\u001B[1;34m(self, unit)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_bound_unit\u001B[39m(\u001B[38;5;28mself\u001B[39m, unit):\n\u001B[1;32m--> 246\u001B[0m     unit \u001B[38;5;241m=\u001B[39m unit\u001B[38;5;241m.\u001B[39mclone()\n\u001B[0;32m    247\u001B[0m     unit\u001B[38;5;241m.\u001B[39minit(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m unit\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit.clone\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclone\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_params())\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit._get_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     74\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001B[39;00m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m---> 76\u001B[0m         (key, \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_param_names()\n\u001B[0;32m     77\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit._get_param_names\u001B[1;34m(cls)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m:\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m []\n\u001B[1;32m---> 70\u001B[0m args, varargs, kw, default \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39mgetargspec(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(args[\u001B[38;5;241m1\u001B[39m:])\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w7MDqIvWib4O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "82be56cc-3ecd-4452-8891-da7480583c5d",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:37.557263Z",
     "start_time": "2024-07-06T10:38:36.262207Z"
    }
   },
   "source": [
    "# 2\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_results = nlp(raw)\n",
    "print(' '.join([token.lemma_ for token in spacy_results]))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENNIS : listen , strange woman lie in pond distribute sword \n",
      " be no basis for a system of government .   Supreme executive power derive from \n",
      " a mandate from the masse , not from some farcical aquatic ceremony .\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVC5gjCRk5bD"
   },
   "source": [
    "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yim_NVYA6MeS"
   },
   "source": [
    "### Part-of-Speech"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t_MamYKqbSk",
    "outputId": "d5dd1e2f-3e0f-4b47-afea-13033e92eb2d"
   },
   "source": [
    "# 1\n",
    "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('не', OpencorporaTag('PRCL')),\n",
       " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
       " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
       " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
       " ('в', OpencorporaTag('PREP')),\n",
       " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
       " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
       " ('нлп,', OpencorporaTag('UNKN')),\n",
       " ('оно\\nпризнать', OpencorporaTag('PRTS,perf,past,pssv neut,sing'))]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Doa85yw6JWea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cef433cd-eb4f-436d-8e72-38c6261325f7"
   },
   "source": [
    "# 2\n",
    "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('DENNIS', 'PROPN'),\n",
       " (':', 'PUNCT'),\n",
       " ('listen', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('strange', 'ADJ'),\n",
       " ('woman', 'NOUN'),\n",
       " ('lie', 'VERB')]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVGJLVjLtFDp",
    "outputId": "ae58edc9-a8e7-4ca9-fb79-a4400600948b"
   },
   "source": [
    "!pip install -q rnnmorph"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.7/19.7 MB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for rnnmorph (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for russian-tagsets (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_"
   ],
   "metadata": {
    "id": "jV1m2K8apIKQ"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ms2yeEFqrtZ",
    "outputId": "1048882b-faed-4b92-b22e-90708ffea574"
   },
   "source": [
    "# 3\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
    "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('не', 'PART', '_'),\n",
       " ('существовать',\n",
       "  'VERB',\n",
       "  'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'),\n",
       " ('научный', 'ADJ', 'Case=Gen|Degree=Pos|Number=Plur'),\n",
       " ('доказательство', 'NOUN', 'Case=Gen|Gender=Neut|Number=Plur'),\n",
       " ('в', 'ADP', '_'),\n",
       " ('польза', 'NOUN', 'Case=Acc|Gender=Fem|Number=Sing'),\n",
       " ('эффективность', 'NOUN', 'Case=Gen|Gender=Fem|Number=Sing')]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Slt2R76Mgk"
   },
   "source": [
    "### Named entities recognition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zvB43ZHT6MhR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "42ed5ca7-08ec-4733-9c59-a9d2f5c0165f"
   },
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0-_oFwwqAwN"
   },
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIwDfmrYOMfi"
   },
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6DaLniC6MhY"
   },
   "source": [
    "#### 20 newsgroups\n",
    "Датасет с 18000 новостей, сгруппированных по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9uS7IJNW6Mhb",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:35:47.638571Z",
     "start_time": "2024-07-06T10:32:09.428068Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MMbagpJE6Mhh",
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2d152337-5672-4889-8ed1-e0e2b157671b",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:35:47.652896Z",
     "start_time": "2024-07-06T10:35:47.641782Z"
    }
   },
   "source": [
    "newsgroups_train.target_names"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QReW1K46Mhn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d1386452-9aac-49ae-f28b-d1457b7dbe97"
   },
   "source": [
    "newsgroups_train.filenames.shape"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZtRIQmNQ4H0"
   },
   "source": [
    "#### Рассмотрим подвыборку"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OhwuCp5B6Mhz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7a608c24-3435-4989-c80c-74a6bfba0ad7",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:36:53.563209Z",
     "start_time": "2024-07-06T10:36:53.271488Z"
    }
   },
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_train.filenames.shape"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034,)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOREsv336MiA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f87455ee-1fac-43b6-db0a-643b5928d898",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:36:56.544616Z",
     "start_time": "2024-07-06T10:36:56.539299Z"
    }
   },
   "source": [
    "print(newsgroups_train.data[0])"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SBnDG-TN6MiF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3c459595-ada9-46a6-83e0-bcda48c4f107",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:36:59.212502Z",
     "start_time": "2024-07-06T10:36:59.206426Z"
    }
   },
   "source": [
    "newsgroups_train.target[:10]"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1], dtype=int64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XlZYpodRYDI"
   },
   "source": [
    "#### TF-IDF(напоминание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohUk2n3jRbNp"
   },
   "source": [
    "$\\mathbb{n}$ - число слов в документе $\\mathbb{d}$;<br>\n",
    "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
    "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
    "$N$ - число документов; <br><br>\n",
    "\n",
    "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
    "<br>\n",
    "<br>\n",
    "Будем считать, что количество слов $\\mathbb{w}$ в документе $\\mathbb{d}$ задается геометрическим распределением с параметром $p = 1 - p(\\mathbb{w}, \\mathbb{d})$:\n",
    "<br>\n",
    "${\\displaystyle \\mathbb {P} (X=n)=(1-p)^{n}p}$\n",
    "<br><br>\n",
    "$P_{bad}(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = {\\displaystyle \\mathbb {P} (X>=n_{\\mathbb{d}\\mathbb{w}})} = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - говорит, насколько вероятно было встретить документ $\\mathbb{d}$ с таким количеством слов $\\mathbb{w}$ с учетом тенденций в наборе документов\n",
    "<br>\n",
    "Понятно, что чем меньше эта вероятность, тем более значимо слово $\\mathbb{w}$ в данном контексте. Также понятно, что чем более длинный текст, тем больше мат ожидание $n_{\\mathbb{d}\\mathbb{w}}$ в тексте, так что нужно отнормировать.\n",
    "<br><br>\n",
    "Для этого рассмотрим новое распределение:\n",
    "<br>\n",
    "${\\displaystyle \\mathbb {P} (Y=k)=(1-p)^{k/n}p}$\n",
    "<br>\n",
    "Это то же геометрическое распределение, но хитрое - если раньше допустимые значения были в [0; n], то стали в [0; 1]. Тем самым мы решили проблему нормировкой.\n",
    "<br><br>\n",
    "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = {\\displaystyle \\mathbb {P} (Y>=n_{\\mathbb{d}\\mathbb{w}})} = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}} / n}$\n",
    "<br><br>\n",
    "Тогда вот наш лосс:<br>\n",
    "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} / n \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
    "\n",
    "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}} / n$ - term frequency;<br>\n",
    "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQvcMiFH6MiM"
   },
   "source": [
    "#### Давайте векторизуем эти тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "98LLAoZO6MiU",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:37:01.578158Z",
     "start_time": "2024-07-06T10:37:01.574070Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXLU0lj6MiY"
   },
   "source": [
    "#### Некоторые параметры:\n",
    "* input : string {‘filename’, ‘file’, ‘content’}\n",
    "*  lowercase : boolean, default True\n",
    "*  preprocessor : callable or None (default)\n",
    "*  tokenizer : callable or None (default)\n",
    "*  stop_words : string {‘english’}, list, or None (default)\n",
    "*  ngram_range : tuple (min_n, max_n)\n",
    "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
    "*  max_features : int or None, default=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-m81BJxZFwJ"
   },
   "source": [
    "#### Перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_f7padHL6MiZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5bae4507-c013-4638-992b-1bb3879f5023"
   },
   "source": [
    "# lowercase\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nf2s4HCY6Mie",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a378fabf-631a-4567-9c46-0a575bb4116a"
   },
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 42307)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2hwlTWapZR8M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a170964d-4cd9-4d52-966b-8fc22b2d7580"
   },
   "source": [
    "vectorizer.get_feature_names_out().shape"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42307,)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AYfpk0ds6Mij",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9399c410-b80c-4e5f-9a7b-73684d626cbe"
   },
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ookt99atZ8sS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "df6140fc-0342-48b1-f327-945c2a13a211"
   },
   "source": [
    "vectorizer.get_feature_names_out()"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['and', 'from', 'in', 'lines', 'of', 'organization', 'subject',\n",
       "       'the', 'to'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2e_h6c0X6Mim",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8c9f2a14-fe7e-47dd-d902-c4d1f3f22090"
   },
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 2391)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUhOyx4NihL0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ca3972b8-83cb-4932-d960-f4e7ad0b457d"
   },
   "source": [
    "# ngram_range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.01, max_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 5181)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer.get_feature_names_out().shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyuNFLiBeZiA",
    "outputId": "3dcc98e4-c976-4b61-ca74-4eba5057e3d9"
   },
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5181,)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer.get_feature_names_out()[1000:1010]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYTH89LepgZS",
    "outputId": "05b6983e-a111-40fa-c904-da7a810d2d03"
   },
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['college', 'color', 'colorado', 'colors', 'com', 'com alink',\n",
       "       'com alink ksand', 'com brian', 'com brian kendig', 'com don'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7074cdSF6MjC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "b7448cc2-b30e-462d-c028-df590a6c40ac",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:38:59.405533Z",
     "start_time": "2024-07-06T10:38:59.371163Z"
    }
   },
   "source": [
    "# стоп-слова, preproc\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preproc_nltk(text):\n",
    "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "\n",
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "preproc_nltk(st)"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m stopwords\n\u001B[0;32m      3\u001B[0m stopWords \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(stopwords\u001B[38;5;241m.\u001B[39mwords(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwordnet\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m wnl \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mWordNetLemmatizer()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreproc_nltk\u001B[39m(text):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m#text = re.sub(f'[{string.punctuation}]', ' ', text)\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nltk' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LIW3hCSy6MjX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "18b107da-0186-4256-b3a5-e996cf060600"
   },
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 10.7 s, sys: 56.1 ms, total: 10.8 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lUmyAzJEB1SU",
    "outputId": "be6cd304-c3b5-4d9f-a893-631b4c8b9709",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:39:09.551790Z",
     "start_time": "2024-07-06T10:39:08.265022Z"
    }
   },
   "source": [
    "# preproc_spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "texts = newsgroups_train.data.copy()\n",
    "\n",
    "def preproc_spacy(text):\n",
    "    spacy_results = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
    "preproc_spacy(st)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C5Ent0nG5zj",
    "outputId": "9ee90ed2-79aa-409d-a44d-d4f730040b0b"
   },
   "source": [
    "%%time\n",
    "new_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
    "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(new_texts)"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 18.9 s, sys: 680 ms, total: 19.6 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "new_texts[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "zTMtlr37rs7e",
    "outputId": "2b46b72c-8af5-4536-bdad-4605ab21ba7e"
   },
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'from : rych@festival.ed.ac.uk ( R Hawkes ) \\n subject : 3ds : where do all the texture rule go ? \\n line : 21 \\n\\n Hi , \\n\\n I have notice that if you only save a model ( with all your mapping plane \\n position carefully ) to a .3ds file that when you reload it after restart \\n 3ds , they be give a default position and orientation .   but if you save \\n to a .prj file their position / orientation be preserve .   do anyone \\n know why this information be not store in the .3ds file ?   nothing be \\n explicitly say in the manual about save texture rule in the .prj file . \\n I would like to be able to read the texture rule information , do anyone have \\n the format for the .PRJ file ? \\n\\n be the .cel file format available from somewhere ? \\n\\n rych \\n\\n = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \\n Rycharde Hawkes \\t\\t\\t\\t email : rych@festival.ed.ac.uk \\n Virtual Environment Laboratory \\n Dept . of psychology \\t\\t\\t Tel   : +44 31 650 3426 \\n Univ . of Edinburgh \\t\\t\\t fax   : +44 31 667 0150 \\n = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \\n'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 73
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lXAPHZA6Mj0"
   },
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uZYcRkQ86Mj1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a04b625c-07b8-4890-d624-cbd64735d355"
   },
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectorizer.get_feature_names_out()[::100]"
   ],
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['000', 'attempt', 'choose', 'engineering', 'human', 'look',\n",
       "       'of this', 'report', 'technology', 'understand'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHTlj3q6Mj6"
   },
   "source": [
    "#### Можем посмотреть на косинусную меру между векторами"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo4fKtAXqCl-",
    "outputId": "13c2a8b2-3e4a-44e4-8bb7-3c711150832a"
   },
   "source": [
    "vectors.shape"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VA8Fn5I46Mi0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fbda044c-eb8d-42fc-ee2a-253a07e5bb22"
   },
   "source": [
    "vector = vectors.todense()[0]\n",
    "(vector != 0).sum()"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kweWqI8ztDwC",
    "outputId": "b8b667d5-b21e-41de-c194-15ac5bb28b0c"
   },
   "source": [
    "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
   ],
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "89.8023598820059"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VsVQhR9y6Mj8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "outputId": "8b14a750-6041-4cca-e0c0-834f23bd7b82"
   },
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "type(vectors)"
   ],
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ],
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix\n",
       "\n",
       "This can be instantiated in several ways:\n",
       "    csr_array(D)\n",
       "        with a dense matrix or rank-2 ndarray D\n",
       "\n",
       "    csr_array(S)\n",
       "        with another sparse matrix S (equivalent to S.tocsr())\n",
       "\n",
       "    csr_array((M, N), [dtype])\n",
       "        to construct an empty matrix with shape (M, N)\n",
       "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
       "\n",
       "    csr_array((data, (row_ind, col_ind)), [shape=(M, N)])\n",
       "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
       "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
       "\n",
       "    csr_array((data, indices, indptr), [shape=(M, N)])\n",
       "        is the standard CSR representation where the column indices for\n",
       "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
       "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
       "        If the shape parameter is not supplied, the matrix dimensions\n",
       "        are inferred from the index arrays.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "dtype : dtype\n",
       "    Data type of the matrix\n",
       "shape : 2-tuple\n",
       "    Shape of the matrix\n",
       "ndim : int\n",
       "    Number of dimensions (this is always 2)\n",
       "nnz\n",
       "    Number of stored values, including explicit zeros\n",
       "data\n",
       "    CSR format data array of the matrix\n",
       "indices\n",
       "    CSR format index array of the matrix\n",
       "indptr\n",
       "    CSR format index pointer array of the matrix\n",
       "has_sorted_indices\n",
       "    Whether indices are sorted\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\n",
       "Sparse matrices can be used in arithmetic operations: they support\n",
       "addition, subtraction, multiplication, division, and matrix power.\n",
       "\n",
       "Advantages of the CSR format\n",
       "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
       "  - efficient row slicing\n",
       "  - fast matrix vector products\n",
       "\n",
       "Disadvantages of the CSR format\n",
       "  - slow column slicing operations (consider CSC)\n",
       "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
       "\n",
       "Canonical Format\n",
       "    - Within each row, indices are sorted by column.\n",
       "    - There are no duplicate entries.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "&gt;&gt;&gt; import numpy as np\n",
       "&gt;&gt;&gt; from scipy.sparse import csr_array\n",
       "&gt;&gt;&gt; csr_array((3, 4), dtype=np.int8).toarray()\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)\n",
       "\n",
       "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
       "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
       "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
       "&gt;&gt;&gt; csr_array((data, (row, col)), shape=(3, 3)).toarray()\n",
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]])\n",
       "\n",
       "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
       "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
       "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
       "&gt;&gt;&gt; csr_array((data, indices, indptr), shape=(3, 3)).toarray()\n",
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]])\n",
       "\n",
       "Duplicate entries are summed together:\n",
       "\n",
       "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
       "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
       "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
       "&gt;&gt;&gt; csr_array((data, (row, col)), shape=(3, 3)).toarray()\n",
       "array([[9, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 4, 0]])\n",
       "\n",
       "As an example of how to construct a CSR matrix incrementally,\n",
       "the following snippet builds a term-document matrix from texts:\n",
       "\n",
       "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
       "&gt;&gt;&gt; indptr = [0]\n",
       "&gt;&gt;&gt; indices = []\n",
       "&gt;&gt;&gt; data = []\n",
       "&gt;&gt;&gt; vocabulary = {}\n",
       "&gt;&gt;&gt; for d in docs:\n",
       "...     for term in d:\n",
       "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
       "...         indices.append(index)\n",
       "...         data.append(1)\n",
       "...     indptr.append(len(indices))\n",
       "...\n",
       "&gt;&gt;&gt; csr_array((data, indices, indptr), dtype=int).toarray()\n",
       "array([[2, 1, 0, 0],\n",
       "       [0, 1, 1, 1]])</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 370);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tS2G0ZZC6MkN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7dc5ec75-cf8e-4c15-a759-631dc63c6c57"
   },
   "source": [
    "dense_vectors = vectors.todense()\n",
    "dense_vectors.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 77
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LGgb5aP76MkU"
   },
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    # v1, v2 (1 x dim)\n",
    "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l_FrKM6k6MkY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150"
   },
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[0])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 79
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L1XF-isH6Mkh"
   },
   "source": [
    "cosines = []\n",
    "for i in range(10):\n",
    "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ODwgYEbe6Mkl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b6959653-9dea-438a-9590-9c2afedceab4"
   },
   "source": [
    "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
    "cosines"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.0000000000000002,\n",
       " 0.043294587352860875,\n",
       " 0.005869835524491915,\n",
       " 0.0935800085948649,\n",
       " 0.042441093346628496,\n",
       " 0.04763556598669193,\n",
       " 0.038723466540658134,\n",
       " 0.22771527506874503,\n",
       " 0.03289646848736767,\n",
       " 0.06184884190504455]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 82
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZyJP3c6Mkq"
   },
   "source": [
    "#### Обучим любую известную модель на полученных признаках"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4RDfl72A6Mks",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "881d3b15-aa8b-479b-ce66-a06e91e47824"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "y_train.shape, y_test.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1627,), (407,))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 83
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vjfwduNp6Mlo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8d86a9ea-2a38-487a-8147-1b2d6f5c7ab6"
   },
   "source": [
    "%%time\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 s, sys: 7.41 ms, total: 5.82 s\n",
      "Wall time: 5.84 s\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N6Evwipx6Mlv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "943c6663-6329-4ad4-d040-1f54b4ea80f7"
   },
   "source": [
    "accuracy_score(y_test, svc.predict(X_test))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9213759213759214"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 85
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6EBZRbXT6Mly",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4"
   },
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "accuracy_score(y_test, sgd.predict(X_test))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8968058968058968"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 86
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OAwBJ0LuPb"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKLGAYPvPJcJ"
   },
   "source": [
    "import gensim.downloader as api\n",
    "embeddings_pretrained = api.load('glove-twitter-25')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fmH3vc7FSCuP",
    "ExecuteTime": {
     "end_time": "2024-07-06T10:43:18.463272Z",
     "start_time": "2024-07-06T10:40:03.484767Z"
    }
   },
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "proc_words = [preproc_spacy(text).split() for text in newsgroups_train.data]\n",
    "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
    "                 size=100,                 # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Word2Vec.__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Word2Vec\n\u001B[0;32m      3\u001B[0m proc_words \u001B[38;5;241m=\u001B[39m [preproc_spacy(text)\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m newsgroups_train\u001B[38;5;241m.\u001B[39mdata]\n\u001B[1;32m----> 4\u001B[0m embeddings_trained \u001B[38;5;241m=\u001B[39m Word2Vec(proc_words, \u001B[38;5;66;03m# data for model to train on\u001B[39;00m\n\u001B[0;32m      5\u001B[0m                  size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,                 \u001B[38;5;66;03m# embedding vector size\u001B[39;00m\n\u001B[0;32m      6\u001B[0m                  min_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,             \u001B[38;5;66;03m# consider words that occured at least 5 times\u001B[39;00m\n\u001B[0;32m      7\u001B[0m                  window\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mwv\n",
      "\u001B[1;31mTypeError\u001B[0m: Word2Vec.__init__() got an unexpected keyword argument 'size'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Lq20widPJcO"
   },
   "source": [
    "def vectorize_sum(comment, embeddings):\n",
    "    \"\"\"\n",
    "    implement a function that converts preprocessed comment to a sum of token vectors\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "\n",
    "    for word in preproc_nltk(comment).split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[f'{word}']\n",
    "\n",
    "    return features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1KaMKBHsSHd",
    "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
   },
   "source": [
    "len(embeddings_trained.index2word)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 102
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "krjpVRsLPJcf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
   },
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1627, 25), (407, 25))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 95
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWhQ007PPJcn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7100737100737101"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 96
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT_Rr4nOUUu8",
    "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
   },
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1627, 100), (407, 100))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 104
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVMeZBLbVMjO",
    "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8402948402948403"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 109
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F_K8NLmDVds1"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
